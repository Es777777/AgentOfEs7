The Emperor Has No Clothes: How to Code Claude Code in 200 Lines of Code\
《皇帝没有衣服：如何用200行代码编写克劳德代码》
=========================

_January 2025  2025年1月_

[![emperor has no clothes](https://www.mihaileric.com/static/emperor_no_clothes-74ca6bae4decd3746d45fec249cad830-36f83.jpeg)](https://www.mihaileric.com/static/emperor_no_clothes-74ca6bae4decd3746d45fec249cad830-36f83.jpeg)

Today AI coding assistants feel like magic. You describe what you want in sometimes barely coherent English, and they read files, edit your project, and write functional code.\
如今，AI 编码助理感觉就像魔法一样。你用有时几乎不连贯的英语描述你想要的东西，他们会读取文件、编辑你的项目并编写函数式代码。

But here’s the thing: the core of these tools isn’t magic. It’s about 200 lines of straightforward Python.\
但问题是：这些工具的核心不是魔法。大约有 200 行简单的 Python。

Let’s build a functional coding agent from scratch.\
让我们从零开始构建一个功能正常的编码代理。

## The Mental Model  心理模型

Before we write any code, let’s understand what’s actually happening when you use a coding agent. It’s essentially just a conversation with a powerful LLM that has a toolbox.\
在我们写代码之前，先了解一下使用编码代理时到底发生了什么。本质上就是和一个强大的大型语言模型对话，它有一个工具箱。

1. **You** send a message (“Create a new file with a hello world function”)\
   **你发送**一条消息（“创建带有 hello world 函数的新文件”）
2. **The LLM** decides it needs a tool and responds with a structured tool call (or multiple tool calls)\
   **LLM** 决定需要一个工具，并以结构化工具调用（或多个工具调用）进行响应
3. **Your program** executes that tool call locally (actually creates the file)\
   **你的程序**是在本地执行这个工具调用（实际上创建文件）
4. **The result** gets sent back to the LLM\
   **结果**会被反馈回 LLM
5. **The LLM** uses that context to continue or respond\
   **LLM** 利用这种上下文继续或做出回应

That’s the whole loop. The LLM never actually touches your filesystem. It just _asks_ for things to happen, and your code makes them happen.\
这就是整个循环。LLM 实际上从未真正触及你的文件系统。它只&#x662F;_&#x8981;&#x6C42;_&#x4E8B;情发生，而你的代码让它们发生。

Three Tools You Need\
你需要的三种工具
--------

Our coding agent fundamentally needs three capabilities:\
我们的编码代理基本上需要三项功能：

* **Read files** so the LLM can see your code\
  **读取文件**以便 LLM 看到你的代码
* **List files** so it can navigate your project\
  **列出文件**以便导航你的项目
* **Edit files** so it can give the directive to create and modify code\
  **编辑文件&#xA0;**，这样它就能发出创建和修改代码的指令

That’s it. Production agents like Claude Code have a few more capabilities including `grep`, `bash`, `websearch`, etc but for our purposes we’ll see that three tools is sufficient to do incredible things.\
就是这样。像 Claude Code 这样的生产代理还有更多功能，比如 `grep`、`bash`、`websearch` 等，但就我们而言，三个工具就足够做了惊人的事情。

Setting Up the Scaffolding\
搭建脚手架
-----

We start with basic imports and an API client. I’m using OpenAI here, but this works with any LLM provider:\
我们从基础导入和 API 客户端开始。我这里用的是 OpenAI，但这对任何 LLM 提供商都适用：

```python
import inspect
import json
import os

import anthropic
from dotenv import load_dotenv
from pathlib import Path
from typing import Any, Dict, List, Tuple

load_dotenv()

claude_client = anthropic.Anthropic(api_key=os.environ["ANTHROPIC_API_KEY"])
```

Some terminal colors to make outputs readable:\
一些端子颜色可让输出可读：

```python
YOU_COLOR = "\u001b[94m"
ASSISTANT_COLOR = "\u001b[93m"
RESET_COLOR = "\u001b[0m"
```

And a utility to resolve file paths (so `file.py` becomes `/Users/you/project/file.py`):\
还有一个工具可以解析文件路径（`file.py` 变成 `/Users/you/project/file.py`）：

```python
def resolve_abs_path(path_str: str) -> Path:
    """
    file.py -> /Users/you/project/file.py
    """
    path = Path(path_str).expanduser()
    if not path.is_absolute():
        path = (Path.cwd() / path).resolve()
    return path
```

## Implementing the Tools  工具的实施

Note you should be detailed about your tool function docstrings as they will be used by the LLM to reason about what tools should be called during the conversation. More on this below.\
注意你应该详细说明你的工具函数文档字符串，因为 LLM 会用这些文档来推断对话中应该调用哪些工具。下面会详细说明。

### Tool 1: Read File 工具1：读取文件

The simplest tool. Take a filename, return its contents:\
最简单的工具。取一个文件名，返回其内容：

```python
def read_file_tool(filename: str) -> Dict[str, Any]:
    """
    Gets the full content of a file provided by the user.
    :param filename: The name of the file to read.
    :return: The full content of the file.
    """
    full_path = resolve_abs_path(filename)
    print(full_path)
    with open(str(full_path), "r") as f:
        content = f.read()
    return {
        "file_path": str(full_path),
        "content": content
    }
```

We return a dictionary because the LLM needs structured context about what happened.\
我们会返回词典，因为 LLM 需要关于发生事情的结构化背景。

### Tool 2: List Files 工具2：列表文件

Navigate directories by listing their contents:\
通过列出目录内容来导航：

```python
def list_files_tool(path: str) -> Dict[str, Any]:
    """
    Lists the files in a directory provided by the user.
    :param path: The path to a directory to list files from.
    :return: A list of files in the directory.
    """
    full_path = resolve_abs_path(path)
    all_files = []
    for item in full_path.iterdir():
        all_files.append({
            "filename": item.name,
            "type": "file" if item.is_file() else "dir"
        })
    return {
        "path": str(full_path),
        "files": all_files
    }
```

### Tool 3: Edit File 工具3：编辑文件

This is the most complex tool, but still straightforward. It handles two cases:\
这是最复杂的工具，但依然简单明了。它处理两种情况：

* **Creating a new file** when `old_str` is empty\
  当 `old_str` 为空时**创建新文件**
* **Replacing text** by finding `old_str` and replacing with `new_str`\
  通过查找 `old_str` 并替换**文本&#xA0;**，再用 `new_str` 替换

```python
def edit_file_tool(path: str, old_str: str, new_str: str) -> Dict[str, Any]:
    """
    Replaces first occurrence of old_str with new_str in file. If old_str is empty,
    create/overwrite file with new_str.
    :param path: The path to the file to edit.
    :param old_str: The string to replace.
    :param new_str: The string to replace with.
    :return: A dictionary with the path to the file and the action taken.
    """
    full_path = resolve_abs_path(path)
    if old_str == "":
        full_path.write_text(new_str, encoding="utf-8")
        return {
            "path": str(full_path),
            "action": "created_file"
        }
    original = full_path.read_text(encoding="utf-8")
    if original.find(old_str) == -1:
        return {
            "path": str(full_path),
            "action": "old_str not found"
        }
    edited = original.replace(old_str, new_str, 1)
    full_path.write_text(edited, encoding="utf-8")
    return {
        "path": str(full_path),
        "action": "edited"
    }
```

The convention here: empty `old_str` means “create this file.” Otherwise, find and replace. Real IDEs add sophisticated fallback behavior when the string isn’t found, but this works.\
这里的惯例是：空 `old_str` 意味着“创建此文件”。否则，就找并替换。真正的 IDE 在找不到字符串时会添加复杂的后备行为，但这确实有效。

## The Tool Registry  工具登记册

We need a way to look up tools by name:\
我们需要一种按名称查找工具的方法：

```python
TOOL_REGISTRY = {
    "read_file": read_file_tool,
    "list_files": list_files_tool,
    "edit_file": edit_file_tool 
}
```

Teaching the LLM About Our Tools\
教授 LLM 关于我们的工具
--------------

The LLM needs to know what tools exist and how to call them. We generate this dynamically from our function signatures and docstrings:\
LLM 需要知道有哪些工具存在，以及如何调用它们。我们通过函数签名和文档字符串动态生成：

```python
def get_tool_str_representation(tool_name: str) -> str:
    tool = TOOL_REGISTRY[tool_name]
    return f"""
    Name: {tool_name}
    Description: {tool.__doc__}
    Signature: {inspect.signature(tool)}
    """

def get_full_system_prompt():
    tool_str_repr = ""
    for tool_name in TOOL_REGISTRY:
        tool_str_repr += "TOOL\n===" + get_tool_str_representation(tool_name)
        tool_str_repr += f"\n{'='*15}\n"
    return SYSTEM_PROMPT.format(tool_list_repr=tool_str_repr)
```

And the system prompt itself:\
系统提示自己：

```python
SYSTEM_PROMPT = """
You are a coding assistant whose goal it is to help us solve coding tasks. 
You have access to a series of tools you can execute. Here are the tools you can execute:

{tool_list_repr}

When you want to use a tool, reply with exactly one line in the format: 'tool: TOOL_NAME({{JSON_ARGS}})' and nothing else.
Use compact single-line JSON with double quotes. After receiving a tool_result(...) message, continue the task.
If no tool is needed, respond normally.
"""
```

This is the key insight: we’re just telling the LLM “here are your tools, here’s the format to call them.” The LLM figures out when and how to use them.\
这是关键的见解：我们只是告诉大型语言模型“这是你的工具，这是调用它们的格式。”LLM 会决定何时以及如何使用它们。

## Parsing Tool Calls  解析工具调用

When the LLM responds, we need to detect if it’s asking us to run a tool:\
当 LLM 响应时，我们需要检测它是否在要求我们运行某个工具：

```python
def extract_tool_invocations(text: str) -> List[Tuple[str, Dict[str, Any]]]:
    """
    Return list of (tool_name, args) requested in 'tool: name({...})' lines.
    The parser expects single-line, compact JSON in parentheses.
    """
    invocations = []
    for raw_line in text.splitlines():
        line = raw_line.strip()
        if not line.startswith("tool:"):
            continue
        try:
            after = line[len("tool:"):].strip()
            name, rest = after.split("(", 1)
            name = name.strip()
            if not rest.endswith(")"):
                continue
            json_str = rest[:-1].strip()
            args = json.loads(json_str)
            invocations.append((name, args))
        except Exception:
            continue
    return invocations
```

Simple text parsing. Look for lines starting with `tool:`, extract the function name and JSON arguments.\
简单的文本解析。找以 `tool：` 开头的行，提取函数名和 JSON 参数。

## The LLM Call  LLM 召集

A thin wrapper around the API:\
API 的薄包装器：

```python
def execute_llm_call(conversation: List[Dict[str, str]]):
    system_content = ""
    messages = []
    
    for msg in conversation:
        if msg["role"] == "system":
            system_content = msg["content"]
        else:
            messages.append(msg)
    
    response = claude_client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2000,
        system=system_content,
        messages=messages
    )
    return response.content[0].text
```

## The Agent Loop  特工环路

Now we put it all together. This is where the “magic” happens:\
现在我们把一切都拼凑起来。这就是“魔法”发生的地方：

```python
def run_coding_agent_loop():
    print(get_full_system_prompt())
    conversation = [{
        "role": "system",
        "content": get_full_system_prompt()
    }]
    while True:
        try:
            user_input = input(f"{YOU_COLOR}You:{RESET_COLOR}:")
        except (KeyboardInterrupt, EOFError):
            break
        conversation.append({
            "role": "user",
            "content": user_input.strip()
        })
        while True:
            assistant_response = execute_llm_call(conversation)
            tool_invocations = extract_tool_invocations(assistant_response)
            if not tool_invocations:
                print(f"{ASSISTANT_COLOR}Assistant:{RESET_COLOR}: {assistant_response}")
                conversation.append({
                    "role": "assistant",
                    "content": assistant_response
                })
                break
            for name, args in tool_invocations:
                tool = TOOL_REGISTRY[name]
                resp = ""
                print(name, args)
                if name == "read_file":
                    resp = tool(args.get("filename", "."))
                elif name == "list_files":
                    resp = tool(args.get("path", "."))
                elif name == "edit_file":
                    resp = tool(args.get("path", "."), 
                                args.get("old_str", ""), 
                                args.get("new_str", ""))
                conversation.append({
                    "role": "user",
                    "content": f"tool_result({json.dumps(resp)})"
                })
```

The structure:  结构：

1. **Outer loop**: Get user input, add to conversation\
   **外部循环&#xA0;**：收集用户意见，补充对话内容

2. **Inner loop**: Call LLM, check for tool invocations\
   **内循环&#xA0;**：调用 LLM，检查工具调用

   * If no tools needed, print response and break inner loop\
     如果不需要工具，打印响应并断开内环
   * If tools needed, execute them, add results to conversation, loop again\
     如果需要工具，就执行它们，把结果加入对话，再循环一次

The inner loop continues until the LLM responds without requesting any tools. This lets the agent chain multiple tool calls (read a file, then edit it, then confirm the edit).\
内循环持续，直到 LLM 响应且不请求任何工具。这允许代理串联多个工具调用（读取文件，编辑，确认编辑）。

## Running It  运行它

```python
if __name__ == "__main__":
    run_coding_agent_loop()
```

Now you can have conversations like:\
现在你可以进行这样的对话：

> **You:** Make me a new file called hello.py and implement hello world in it\
> **你：** 给我创建一个叫 hello.py 的新文件，并在里面实现 Hello World。

Agent calls _edit\_file_ with path=“hello.py”, old\_str="", new\_str=“print(‘Hello World’)”\
代理调用 _edit\_file_ 时 path=“hello.py”， old\_str=“”， new\_str=“print（'Hello World'）”

> **Assistant:** Done! Created hello.py with a hello world implementation.\
> **助理：** 完成！用 Hello World 实现创建了 hello.py。

Or multi-step interactions:\
或者多步交互：

> **You:** Edit hello.py and add a function for multiplying two numbers\
> **你：** 编辑 hello.py 并添加一个函数来乘两个数字

Agent calls _read\_file_ to see current contents. Agent calls _edit\_file_ to add the function.\
客服打电话给 _read\_file_ 查看当前邮件内容。代理调用 _edit\_file_ 来添加该函数。

> **Assistant:** Added a multiply function to hello.py.\
> **助理：** 给 hello.py 加了乘法函数。

What We Built vs. Production Tools\
我们构建的与生产工具的比较
-------------

This is about 200 lines. Production tools like Claude Code add:\
大约有 200 行。生产工具如 Claude Code 增加了：

* **Better error handling** and fallback behaviors\
  **更好的错误处理**和后备行为
* **Streaming responses** for better UX\
  流**式回复**以提升用户体验
* **Smarter context management** (summarizing long files, etc.)\
  **更智能的上下文管理&#xA0;**（如总结长文件等）
* **More tools** (run commands, search codebase, etc.)\
  **更多工具&#xA0;**（运行命令、搜索代码库等）
* **Approval workflows** for destructive operations\
  破坏性作审**批流程**

But the core loop? It’s exactly what we built here. The LLM decides what to do, your code executes it, results flow back. That’s the whole architecture.\
但核心循环呢？这正是我们在这里建造的。LLM 决定做什么，你的代码执行，结果反馈。这就是整个架构。

## Try It Yourself  你自己试试

The [full source](https://shorturl.at/HmMeI) is about 200 lines. Swap in your preferred LLM provider, adjust the system prompt, add more tools as an exercise. You’ll be surprised how capable this simple pattern is.\
[完整源](https://shorturl.at/HmMeI)大约有 200 行。换上你喜欢的 LLM 供应商，调整系统提示，增加更多工具作为练习。你会惊讶于这个简单的图案有多么强大。

_This is part of the first module in my modern AI software engineering course based on my Stanford lectures._
